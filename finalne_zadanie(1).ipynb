{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPkKql1wKxTc",
        "outputId": "4d52f106-c83f-44d6-8299-91840495cb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Generation 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 2/5\n",
            "Generation 3/5\n",
            "Generation 4/5\n",
            "Generation 5/5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_neurons': 256, 'activation': 'relu', 'learning_rate': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Function to create the neural network model\n",
        "def create_model(num_neurons, activation, learning_rate):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(num_neurons, activation=activation),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Defining the parameter space for the genetic algorithm\n",
        "param_space = {\n",
        "    'num_neurons': [32, 64, 128, 256],\n",
        "    'activation': ['relu', 'sigmoid', 'tanh'],\n",
        "    'learning_rate': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Genetic Algorithm Parameters\n",
        "population_size = 10\n",
        "generations = 5\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Function to initialize the population\n",
        "def initialize_population():\n",
        "    population = []\n",
        "    for _ in range(population_size):\n",
        "        individual = {\n",
        "            'num_neurons': np.random.choice(param_space['num_neurons']),\n",
        "            'activation': np.random.choice(param_space['activation']),\n",
        "            'learning_rate': np.random.choice(param_space['learning_rate'])\n",
        "        }\n",
        "        population.append(individual)\n",
        "    return population\n",
        "\n",
        "# Fitness function to evaluate an individual's performance\n",
        "def fitness_function(individual):\n",
        "    model = create_model(individual['num_neurons'], individual['activation'], individual['learning_rate'])\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, verbose=0)\n",
        "    accuracy = history.history['val_accuracy'][-1]  # Last validation accuracy\n",
        "    return accuracy\n",
        "\n",
        "# Tournament selection function\n",
        "def selection(population, fitness):\n",
        "    selected = np.random.choice(population, size=2, replace=False)\n",
        "    return max(selected, key=lambda x: fitness[str(x)])\n",
        "\n",
        "# Crossover function to combine two parents\n",
        "def crossover(parent1, parent2):\n",
        "    child = {}\n",
        "    for key in parent1.keys():\n",
        "        child[key] = np.random.choice([parent1[key], parent2[key]])\n",
        "    return child\n",
        "\n",
        "# Mutation function to introduce random changes in individuals\n",
        "def mutate(individual):\n",
        "    if np.random.rand() < mutation_rate:\n",
        "        individual['num_neurons'] = np.random.choice(param_space['num_neurons'])\n",
        "    if np.random.rand() < mutation_rate:\n",
        "        individual['activation'] = np.random.choice(param_space['activation'])\n",
        "    if np.random.rand() < mutation_rate:\n",
        "        individual['learning_rate'] = np.random.choice(param_space['learning_rate'])\n",
        "    return individual\n",
        "\n",
        "# Main Genetic Algorithm Loop\n",
        "def genetic_algorithm():\n",
        "    population = initialize_population()\n",
        "    for generation in range(generations):\n",
        "        print(f\"Generation {generation + 1}/{generations}\")\n",
        "        fitness_scores = {str(individual): fitness_function(individual) for individual in population}\n",
        "        new_population = []\n",
        "        for _ in range(population_size // 2):\n",
        "            parent1 = selection(population, fitness_scores)\n",
        "            parent2 = selection(population, fitness_scores)\n",
        "            child1 = mutate(crossover(parent1, parent2))\n",
        "            child2 = mutate(crossover(parent1, parent2))\n",
        "            new_population.extend([child1, child2])\n",
        "        population = new_population\n",
        "    best_individual = max(population, key=lambda x: fitness_function(x))\n",
        "    return best_individual\n",
        "\n",
        "# Run the genetic algorithm to find the best hyperparameters\n",
        "best_params = genetic_algorithm()\n",
        "best_params\n"
      ]
    }
  ]
}